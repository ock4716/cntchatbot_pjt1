import streamlit as st
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¶€ë™ì‚° ë¦¬í¬íŠ¸ Q&A AI",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    /* ê¸°ë³¸ ë°°ê²½ìƒ‰ (ì „ì²´ ì•±) */
    .stApp {
        background-color: white;
        color: #000000;
    }
    
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ (ì§„í•œ ì²­ë¡ìƒ‰) */
    [data-testid="stSidebar"] {
        background-color: #0e7490;
    }
    
    /* ì‚¬ì´ë“œë°” ë‚´ë¶€ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    [data-testid="stSidebar"] .stButton button {
        background-color: #164e63;
        color: white;
        border: none;
        width: 100%;
        text-align: left;
        padding: 12px;
        margin: 5px 0;
        border-radius: 5px;
        box-shadow: none; 
    }
    
    [data-testid="stSidebar"] .stButton button:hover {
        background-color: #0e7490; 
    }
    
    /* ì±—ë´‡ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .bot-message {
        background-color: #e0f7fa;
        color: #000000 !important;
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 5px solid #0e7490; 
    }
    
    /* ì‚¬ìš©ì ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .user-message {
        background-color: #f0f0f0;
        color: #000000 !important;
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
        text-align: right;
    }
    
    /* ì°¸ê³ ìë£Œ ë°•ìŠ¤ */
    .reference-box {
        background-color: #fefce8; 
        color: #000000 !important;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        border-left: 4px solid #eab308;
    }
    
    /* ì‚¬ì´ë“œë°” í—¤ë” ìŠ¤íƒ€ì¼ */
    .header-icon {
        display: flex;
        align-items: center;
        gap: 10px;
        color: white;
        font-size: 1.5em;
        font-weight: bold;
        padding: 10px 15px; 
    }
    
    /* ì„¤ì • ìŠ¬ë¼ì´ë” ìº¡ì…˜ */
    [data-testid="stSidebar"] div.stCaption {
        color: #e0f7fa !important; 
    }
    
    /* ì¼ë°˜ í…ìŠ¤íŠ¸ (ì‚¬ì´ë“œë°”) */
    [data-testid="stSidebar"] h3, [data-testid="stSidebar"] label {
        color: white !important;
    }

    /* ë©”ì¸ ì˜ì—­ ì œëª©/ë¶€ì œëª© */
    h1, h2, h3, h4, h5, h6 {
        color: #000000 !important;
    }
    
    /* ì±„íŒ… ì…ë ¥ì°½ */
    [data-testid="stChatInput"] input,
    [data-testid="stChatInput"] textarea {
        color: #000000 !important;
        background-color: white !important;
    }
    
    /* info ë°•ìŠ¤ */
    .stAlert.info {
        background-color: #f0f0f0; 
        border-left-color: #0e7490;
        color: #000000 !important;
    }
    
    /* íƒ­ ë©”ë‰´ ìŠ¤íƒ€ì¼ */
    .stTabs [data-testid="stTab"] {
        color: #000000 !important;
        background-color: transparent !important;
    }

    /* ì„ íƒëœ íƒ­ì˜ ë°‘ì¤„ ìƒ‰ìƒ (ë¹¨ê°„ìƒ‰) */
    .stTabs [data-testid="stTab"][aria-selected="true"] {
        border-bottom: 2px solid red !important;
        color: red !important;
    }

    .stTabs [data-testid="stTab"][aria-selected="false"] {
        border-bottom: 2px solid transparent !important;
    }

    /* ê¸°íƒ€ ìº¡ì…˜/ì‘ì€ ê¸€ì”¨ */
    .stCaption, .stMarkdown small, .stMarkdown p {
        color: #000000 !important;
    }
    
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'current_section' not in st.session_state:
    st.session_state.current_section = "ì„œìš¸ ì•„íŒŒíŠ¸ ì£¼ê°„ ì‹œí™©"

if 'references' not in st.session_state:
    st.session_state.references = []

if 'qa_system' not in st.session_state:
    st.session_state.qa_system = None

if 'search_engine' not in st.session_state:
    st.session_state.search_engine = None

if 'user_questions' not in st.session_state:
    st.session_state.user_questions = []

if 'current_visualization' not in st.session_state:
    st.session_state.current_visualization = None

# .envì—ì„œ OpenAI API í‚¤ ë¡œë“œ ë° QA ì‹œìŠ¤í…œ ìë™ ì´ˆê¸°í™”
if st.session_state.qa_system is None:
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        try:
            from src.s8_qa_system_integrated import QASystem
            st.session_state.qa_system = QASystem(openai_api_key=api_key, model="gpt-4o")
            print("âœ… QA ì‹œìŠ¤í…œì´ .envì˜ API í‚¤ë¡œ ìë™ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except ImportError:
            st.error("âš ï¸ qa_system_integrated.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ QA ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    else:
        st.warning("âš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# Search Engine ì´ˆê¸°í™”
if st.session_state.search_engine is None:
    import json
    import faiss
    from pathlib import Path
    
    try:
        # ê²½ë¡œ ì„¤ì •
        vector_store_path = Path("data/vector_store/kb")
        processed_path = Path("data/processed/kb")
        
        faiss_index_path = vector_store_path / "faiss_index.bin"
        metadata_path = vector_store_path / "metadata.json"
        chunks_path = processed_path / "kb_report_chunks.json"
        
        # íŒŒì¼ ë¡œë“œ
        faiss_index = faiss.read_index(str(faiss_index_path))
        
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        with open(chunks_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        
        # EmbeddingManager ì´ˆê¸°í™”
        from src.s5_embedding_manager import EmbeddingManager
        from src.s6_search_engine import SearchEngine
        
        api_key = os.getenv("OPENAI_API_KEY")
        embedding_manager = EmbeddingManager(
            openai_api_key=api_key,
            institution="kb"  
        )
        # SearchEngine ì´ˆê¸°í™”
        st.session_state.search_engine = SearchEngine(
            faiss_index=faiss_index,
            metadata=metadata,
            chunks=chunks,
            embedding_manager=embedding_manager
        )
        print("âœ… Search Engineì´ ìë™ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ Search Engine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.session_state.search_engine = None

# RAG ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(query: str, temperature: float, top_k: int, use_conversation: bool = True) -> tuple:
    """
    RAG íŒŒì´í”„ë¼ì¸ + ì‹œê°í™” ì§€ì›
    
    Returns:
        (ì‘ë‹µ ë”•ì…”ë„ˆë¦¬, ì°¸ê³  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸)
    """
    if st.session_state.qa_system is None:
        response = {"answer_type": "text", "text_response": "âš ï¸ QA ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "visualization": None}
        return response, []
    
    if st.session_state.search_engine is None:
        response = {"answer_type": "text", "text_response": "âš ï¸ ë²¡í„° DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "visualization": None}
        return response, []
    
    try:
        # 1. ê²€ìƒ‰ ìˆ˜í–‰
        search_results = st.session_state.search_engine.hybrid_search(query, top_k=top_k)
        
        # 2. QASystemìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì‹œê°í™” í¬í•¨)
        qa_system = st.session_state.qa_system
        
        result_dict = qa_system.answer_question(
            query=query,
            search_results=search_results,
            rewrite=False,
            use_history=use_conversation,
            temperature=temperature
        )
        
        # 3. ì°¸ê³  ë¬¸ì„œ ì •ë¦¬
        references = []
        for i, result in enumerate(search_results[:top_k], 1):
            metadata = result.get("metadata", {})
            content = result.get("content", "")
            
            institution = metadata.get("institution", "unknown")
            institution_map = {
                "hd": "HD í˜„ëŒ€",
                "kb": "KBê¸ˆìœµ",
                "khi": "KHI ì£¼íƒê¸ˆìœµ"
            }
            source_name = institution_map.get(institution, institution)
            
            doc_type_map = {
                "text": "ë³¸ë¬¸",
                "table": "í‘œ",
                "image": "ê·¸ë˜í”„"
            }
            doc_type = doc_type_map.get(metadata.get("doc_type"), "ë³¸ë¬¸")
            
            references.append({
                "page": metadata.get("page", "N/A"),
                "text": content[:300],
                "source": f"{source_name} - {doc_type}",
                "institution": source_name
            })
        
        return result_dict, references
        
    except Exception as e:
        print(f"Error in generate_response: {e}")
        error_response = {
            "answer_type": "text",
            "text_response": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "visualization": None
        }
        return error_response, []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown('<div class="header-icon">ğŸ›ï¸ ë¶€ë™ì‚° ë¦¬í¬íŠ¸ Q&A AI</div>', unsafe_allow_html=True)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    if st.session_state.qa_system:
        st.success("âœ… QA ì‹œìŠ¤í…œ ì—°ê²°ë¨")
    else:
        st.error("âŒ QA ì‹œìŠ¤í…œ ë¯¸ì—°ê²°")
    
    if st.session_state.search_engine:
        st.success("âœ… ë²¡í„° DB ì—°ê²°ë¨")
    else:
        st.warning("âš ï¸ ë²¡í„° DB ë¯¸ì—°ê²°")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¦¬ì…‹ ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        if st.session_state.qa_system:
            st.session_state.qa_system.clear_history()
        st.session_state.current_visualization = None
        st.rerun()
    
    st.markdown("---")
    
    # ìµœê·¼ ë¬¼ì–´ë³¸ ì§ˆë¬¸
    st.markdown("### ğŸ’¬ ìµœê·¼ ë¬¼ì–´ë³¸ ì§ˆë¬¸")
    
    recent_questions = st.session_state.user_questions[-4:][::-1]
    
    if recent_questions:
        for idx, question in enumerate(recent_questions):
            display_question = question if len(question) <= 30 else question[:27] + "..."
            if st.button(display_question, key=f"recent_q_{idx}", use_container_width=True):
                st.session_state.selected_question = question
    else:
        st.caption("ì•„ì§ ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    st.markdown("### âš™ï¸ ì„¤ì •")
    
    temperature = st.slider(
        "ê²€ìƒ‰ ë¯¼ê°ë„ (Temperature)",
        min_value=0.0,
        max_value=1.0,
        value=0.3,
        step=0.1,
        help="ë‚®ì„ìˆ˜ë¡ ì •í™•í•˜ê³  ì¼ê´€ëœ ë‹µë³€"
    )
    
    top_k = st.slider(
        "ì°¸ê³ í•  í˜ì´ì§€ ìˆ˜ (Top-k)",
        min_value=1,
        max_value=10,
        value=5,
        step=1,
        help="ê²€ìƒ‰í•  ë¬¸ì„œ ì²­í¬ ìˆ˜"
    )
    
    use_conversation = st.checkbox(
        "ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©",
        value=True,
        help="ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€"
    )

# ë©”ì¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([2, 1])

with col1:
    st.title("ğŸ’¬ ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡")
    
    # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€
    if len(st.session_state.messages) == 0:
        st.markdown("""
        <div class="bot-message">
            <strong>ğŸ›ï¸ ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡</strong><br><br>
            ì•ˆë…•í•˜ì„¸ìš”! ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡ì…ë‹ˆë‹¤. ì§€ì—­(ì˜ˆ: ì„œìš¸ ê°•ë‚¨êµ¬), ê±°ë˜ì¢…ë¥˜
            (ë§¤ë§¤/ì „ì„¸), ê¸°ê°„(ì˜ˆ: ìµœê·¼ 3ê°œì›”) ë“±ì„ ì…ë ¥í•˜ì‹œë©´ ìµœì‹  ë™í–¥ ìš”ì•½ì„ ì œ
            ê³µí•©ë‹ˆë‹¤. <br><br>
            "ì§€ì—­ë³„ ê°€ê²©ì„ í‘œë¡œ ë³´ì—¬ì¤˜", "ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜" ê°™ì€ ìš”ì²­ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤!
        </div>
        """, unsafe_allow_html=True)
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f'<div class="user-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
        else:
            # í…ìŠ¤íŠ¸ ì‘ë‹µ
            st.markdown(f'<div class="bot-message"><strong>ğŸ›ï¸ ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡</strong><br><br>{message["content"]}</div>', 
                       unsafe_allow_html=True)
            
            # ì°¸ê³ ìë£Œ í‘œì‹œ
            if "references" in message and message["references"]:
                with st.expander("ğŸ” ê·¼ê±° ìë£Œ ë° ë°ì´í„° í™•ì¸"):
                    for ref in message["references"]:
                        st.markdown(f"""
                        <div class="reference-box">
                            <strong>REFERENCE TEXT (PAGE {ref['page']})</strong><br>
                            <small>ì¶œì²˜: {ref.get('source', 'N/A')}</small><br><br>
                            "{ref['text']}"
                        </div>
                        """, unsafe_allow_html=True)
    
    # ìµœê·¼ ì§ˆë¬¸ ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
    if 'selected_question' in st.session_state:
        user_input = st.session_state.selected_question
        del st.session_state.selected_question
    else:
        user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ) 2024ë…„ 1ë¶„ê¸° ì„œìš¸ ì§€ì—­ë³„ ì£¼íƒ ê°€ê²© ë³€ë™ë¥ ì€?")
    
    if user_input:
        # ì‚¬ìš©ì ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.user_questions.append(user_input)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user",
            "content": user_input
        })
        
        # AI ì‘ë‹µ ìƒì„± (ì‹œê°í™” í¬í•¨)
        result_dict, references = generate_response(
            user_input, 
            temperature, 
            top_k,
            use_conversation
        )
        
        # ì‘ë‹µ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": result_dict["text_response"],
            "references": references,
            "visualization": result_dict.get("visualization")
        })
        
        # ì‹œê°í™”ê°€ ìˆìœ¼ë©´ ì„¸ì…˜ì— ì €ì¥
        if result_dict.get("visualization"):
            st.session_state.current_visualization = result_dict["visualization"]
        
        st.rerun()

with col2:
    st.markdown("### ì‹œê°í™” ë¯¸ë¦¬ë³´ê¸°")
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“Š í‘œ ë³´ê¸°", "ğŸ“ˆ ì°¨íŠ¸ ë³´ê¸°"])
    
    # ìµœì‹  ë©”ì‹œì§€ì—ì„œ ì‹œê°í™” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    visualization_data = None
    if st.session_state.messages:
        last_assistant_messages = [msg for msg in st.session_state.messages if msg["role"] == "assistant"]
        if last_assistant_messages and "visualization" in last_assistant_messages[-1]:
            visualization_data = last_assistant_messages[-1]["visualization"]
    
    with tab1:
        if visualization_data and visualization_data.get("type") == "table":
            from src.s8_qa_system_integrated import VisualizationRenderer
            VisualizationRenderer.render_table_streamlit(visualization_data)
        else:
            st.info("í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'í‘œë¡œ ë³´ì—¬ì¤˜' ê°™ì€ ìš”ì²­ì„ í•´ë³´ì„¸ìš”!")
    
    with tab2:
        if visualization_data and visualization_data.get("type") in ["bar", "barh", "line", "pie"]:
            from src.s8_qa_system_integrated import VisualizationRenderer
            VisualizationRenderer.render_chart_streamlit(visualization_data)
        else:
            st.info("ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜' ê°™ì€ ìš”ì²­ì„ í•´ë³´ì„¸ìš”!")
    
    st.markdown("---")
    st.markdown("### ì¶œì²˜ / ë ˆí¼ëŸ°ìŠ¤")
    st.caption("ê²€ìƒ‰ ê²°ê³¼ì—ì„œ êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ì¶œì²˜ ë¦¬ìŠ¤íŠ¸")
    
    # ìµœì‹  ë©”ì‹œì§€ì˜ ë ˆí¼ëŸ°ìŠ¤ í‘œì‹œ
    if st.session_state.messages:
        last_messages = [msg for msg in st.session_state.messages if msg["role"] == "assistant"]
        if last_messages and "references" in last_messages[-1]:
            references = last_messages[-1]["references"]
            if references:
                for idx, ref in enumerate(references, 1):
                    source = ref.get("source", "N/A")
                    page = ref.get("page", "N/A")
                    st.markdown(f"**[{idx}]** {source} ({page}í˜ì´ì§€)")
            else:
                st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    pass