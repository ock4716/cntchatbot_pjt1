"""
search_engine.py
[5ë‹¨ê³„] ê²€ìƒ‰ ì—”ì§„

í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(ë²¡í„° + BM25)ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
- ë²¡í„° ê²€ìƒ‰ (FAISS)
- í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Reciprocal Rank Fusion)
"""

import numpy as np
import faiss
from typing import List, Dict
from rank_bm25 import BM25Okapi
import re


class SearchEngine:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤ (ë²¡í„° + í‚¤ì›Œë“œ + RRF)"""
    
    def __init__(self, 
                 faiss_index: faiss.Index,
                 metadata: List[Dict],
                 chunks: List[Dict],
                 embedding_manager=None):
        """
        SearchEngine ì´ˆê¸°í™”
        
        Args:
            faiss_index: FAISS ì¸ë±ìŠ¤
            metadata: ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            chunks: ì²­í¬ ë¦¬ìŠ¤íŠ¸ (BM25ìš©)
            embedding_manager: EmbeddingManager ì¸ìŠ¤í„´ìŠ¤ (ì¿¼ë¦¬ ì„ë² ë”©ìš©)
        """
        self.faiss_index = faiss_index
        self.metadata = metadata
        self.chunks = chunks
        self.embedding_manager = embedding_manager
        
        # BM25 ì¸ë±ìŠ¤ ìƒì„±
        print("ğŸ”§ BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        self._build_bm25_index()
        
        print("âœ“ SearchEngine ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  - FAISS ë²¡í„° ìˆ˜: {faiss_index.ntotal}")
        print(f"  - BM25 ë¬¸ì„œ ìˆ˜: {len(self.bm25_corpus)}")
    
    def _tokenize_korean(self, text: str) -> List[str]:
        """
        í•œê¸€ í…ìŠ¤íŠ¸ í† í°í™” (ê°„ë‹¨í•œ ë°©ë²•)
        
        Args:
            text: í† í°í™”í•  í…ìŠ¤íŠ¸
        
        Returns:
            í† í° ë¦¬ìŠ¤íŠ¸
        """
        # ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        tokens = re.findall(r'\w+', text.lower())
        return tokens
    
    def _build_bm25_index(self):
        """BM25 ì¸ë±ìŠ¤ êµ¬ì¶•"""
        # ê° ì²­í¬ì˜ contentë¥¼ í† í°í™”
        self.bm25_corpus = []
        for chunk in self.chunks:
            content = chunk.get('content', '')
            tokens = self._tokenize_korean(content)
            self.bm25_corpus.append(tokens)
        
        # BM25 ì¸ë±ìŠ¤ ìƒì„±
        self.bm25 = BM25Okapi(self.bm25_corpus)
        print(f"âœ“ BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {len(self.bm25_corpus)}ê°œ ë¬¸ì„œ")
    
    def vector_search(self, 
                     query: str,
                     top_k: int = 10) -> List[Dict]:
        """
        ë²¡í„° ê²€ìƒ‰ (FAISS)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.embedding_manager:
            raise ValueError("EmbeddingManagerê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedding_manager.embed_text(query)
        query_embedding = query_embedding.reshape(1, -1).astype('float32')
        
        # FAISS ê²€ìƒ‰
        distances, indices = self.faiss_index.search(query_embedding, top_k)
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):
            if idx < len(self.metadata):
                result = {
                    "rank": i + 1,
                    "chunk_id": self.metadata[idx]["chunk_id"],
                    "content": self.metadata[idx]["content"],
                    "metadata": self.metadata[idx]["metadata"],
                    "score": float(1 / (1 + distance)),  # ê±°ë¦¬ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜
                    "search_type": "vector"
                }
                results.append(result)
        
        return results
    
    def keyword_search(self,
                      query: str,
                      top_k: int = 10) -> List[Dict]:
        """
        í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ì¿¼ë¦¬ í† í°í™”
        query_tokens = self._tokenize_korean(query)
        
        # BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
        scores = self.bm25.get_scores(query_tokens)
        
        # ìƒìœ„ top_kê°œ ì„ íƒ
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for i, idx in enumerate(top_indices):
            if scores[idx] > 0:  # ìŠ¤ì½”ì–´ê°€ 0ë³´ë‹¤ í° ê²ƒë§Œ
                chunk = self.chunks[idx]
                result = {
                    "rank": i + 1,
                    "chunk_id": chunk["chunk_id"],
                    "content": chunk["content"],
                    "metadata": chunk["metadata"],
                    "score": float(scores[idx]),
                    "search_type": "keyword"
                }
                results.append(result)
        
        return results
    
    def reciprocal_rank_fusion(self,
                               vector_results: List[Dict],
                               keyword_results: List[Dict],
                               k: int = 60) -> List[Dict]:
        """
        Reciprocal Rank Fusion (RRF) ì•Œê³ ë¦¬ì¦˜
        
        ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì ìœ¼ë¡œ ìœµí•©í•©ë‹ˆë‹¤.
        RRF ê³µì‹: score = 1/(k + rank_vector) + 1/(k + rank_keyword)
        
        Args:
            vector_results: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
            keyword_results: í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼
            k: RRF ìƒìˆ˜ (ê¸°ë³¸ê°’ 60, ë‚®ì„ìˆ˜ë¡ ìƒìœ„ ë­í¬ì— ê°€ì¤‘ì¹˜)
        
        Returns:
            ìœµí•©ëœ ê²€ìƒ‰ ê²°ê³¼
        """
        # chunk_idë³„ë¡œ ì ìˆ˜ ê³„ì‚°
        chunk_scores = {}
        chunk_data = {}
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        for result in vector_results:
            chunk_id = result["chunk_id"]
            rank = result["rank"]
            rrf_score = 1 / (k + rank)
            
            chunk_scores[chunk_id] = chunk_scores.get(chunk_id, 0) + rrf_score
            chunk_data[chunk_id] = result
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        for result in keyword_results:
            chunk_id = result["chunk_id"]
            rank = result["rank"]
            rrf_score = 1 / (k + rank)
            
            chunk_scores[chunk_id] = chunk_scores.get(chunk_id, 0) + rrf_score
            if chunk_id not in chunk_data:
                chunk_data[chunk_id] = result
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_chunks = sorted(chunk_scores.items(), key=lambda x: x[1], reverse=True)
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for i, (chunk_id, score) in enumerate(sorted_chunks):
            result = chunk_data[chunk_id].copy()
            result["rank"] = i + 1
            result["rrf_score"] = float(score)
            result["search_type"] = "hybrid"
            results.append(result)
        
        return results
    
    def hybrid_search(self,
                     query: str,
                     top_k: int = 10) -> List[Dict]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ + RRF)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        
        Returns:
            ìµœì¢… ê²€ìƒ‰ ê²°ê³¼
        """
        # 1. ë²¡í„° ê²€ìƒ‰ (ì˜ë¯¸ì  ìœ ì‚¬ë„)
        vector_results = self.vector_search(query, top_k=top_k*2)
        
        # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­)
        keyword_results = self.keyword_search(query, top_k=top_k*2)
        
        # 3. RRFë¡œ ìœµí•©
        hybrid_results = self.reciprocal_rank_fusion(vector_results, keyword_results)
        
        # 4. ìƒìœ„ top_kê°œë§Œ ë°˜í™˜
        return hybrid_results[:top_k]